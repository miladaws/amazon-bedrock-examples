{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28541779-62cc-423b-99f5-92061e00fcbd",
   "metadata": {},
   "source": [
    "## Fine-Tuning and Deploying Custom Models on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a827fab-f3ed-41d2-aa05-363a86c6b72b",
   "metadata": {},
   "source": [
    "### Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2400f920-4ea0-4f76-8b69-011965a81d24",
   "metadata": {},
   "source": [
    "This notebook will guide you through the process of creating the necessary resources and preparing the datasets for fine-tuning the Cohere  command-light-text-v14 model using Amazon Bedrock. By the end of this notebook, you will have created an IAM role, an S3 bucket, and training, validation, and testing datasets in the required format for the fine-tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c37bd4-e115-4bd1-8667-60cc3705f549",
   "metadata": {},
   "source": [
    "## Prerequisites\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d96bd-49c2-4641-84e0-73c23d2750c8",
   "metadata": {},
   "source": [
    "- Make sure that that you have access to Cohere's command-light-text-v14. You can enable it in Amazon Bedrock. \n",
    "- Make sure that the AWS SDK is already installed and configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7e6f03-5226-4696-a2ec-aeb54cd06a24",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36faee07-2d4f-4bad-b9a8-1f0efac96b25",
   "metadata": {},
   "source": [
    "Install `boto3` to build and manager resources on AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cdc8b-5885-4436-9115-ca74ea5d46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99a3e4-1aac-491a-b5c5-417baae46e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca73c7d-edf3-40b8-a57e-69f73b137d1c",
   "metadata": {},
   "source": [
    "## Step 2: Fetch Biomedical Data from PubMed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d06e4-7030-4562-9aaf-44d5147e60f0",
   "metadata": {},
   "source": [
    "We will define a function to retrieve abstracts from PubMed using the Entrez Programming Utilities (E-utilities). These abstracts will be used as the input data for our fine-tuning task.\n",
    "PubMed is a free resource that provides access to a vast collection of biomedical literature, including abstracts and full-text articles. URL: https://www.ncbi.nlm.nih.gov/home/develop/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb55cf-bac9-4772-b1aa-5f4d6d8f7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pubmed_abstracts(query, num_records):\n",
    "    \"\"\"\n",
    "    Fetches abstracts from PubMed based on a search query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search term for PubMed.\n",
    "        num_records (int): Number of abstracts to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries with 'prompt' and 'completion' keys.\n",
    "    \"\"\"\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "    search_url = f\"{base_url}esearch.fcgi?db=pubmed&term={query}&retmax={num_records}&retmode=json\"\n",
    "    \n",
    "    response = requests.get(search_url)\n",
    "    id_list = response.json()['esearchresult']['idlist']\n",
    "    \n",
    "    abstracts = []\n",
    "    for pubmed_id in id_list:\n",
    "        fetch_url = f\"{base_url}efetch.fcgi?db=pubmed&id={pubmed_id}&retmode=xml\"\n",
    "        fetch_response = requests.get(fetch_url)\n",
    "        fetch_data = fetch_response.text\n",
    "        \n",
    "        # Extract abstract from XML\n",
    "        start = fetch_data.find(\"<AbstractText>\") + len(\"<AbstractText>\")\n",
    "        end = fetch_data.find(\"</AbstractText>\")\n",
    "        abstract = fetch_data[start:end]\n",
    "        \n",
    "        # Only add valid abstracts\n",
    "        if abstract:\n",
    "            abstracts.append({\n",
    "                \"prompt\": abstract,  # Input for model fine-tuning\n",
    "                \"completion\": \"Summarized abstract\"  # Placeholder for model completion task\n",
    "            })\n",
    "    \n",
    "    return abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dace147-139f-45ce-8dec-cdf921c58168",
   "metadata": {},
   "source": [
    "Fetch 100 PubMed abstracts related to diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f1296-3734-49b3-8f42-374799465216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 100 PubMed abstracts related to diabetes\n",
    "query = \"diabetes\"\n",
    "abstracts_data = fetch_pubmed_abstracts(query, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608fbb9f-35b1-4d71-9a71-0d187dda2125",
   "metadata": {},
   "source": [
    "## Step 3: Save the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a17e9d-6155-42b7-9301-8a4412143313",
   "metadata": {},
   "source": [
    "We will save the fetched abstracts in JSONL format for use in the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c70f27-01d5-4f6e-ba4e-91c31ceaedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path\n",
    "abstracts_file = 'pubmed_abstracts.jsonl'\n",
    "output_file_path = 'dataset/' + abstracts_file\n",
    "output_dir = os.path.dirname(output_file_path)\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save the fetched abstracts to a JSONL file\n",
    "try:\n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        for entry in abstracts_data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "    print(f\"File saved successfully to {output_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86dc416-aca7-491c-94f2-02a47b4db306",
   "metadata": {},
   "source": [
    "## Step 4: Upload the Dataset to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2f1d9-8fb6-4250-b7ae-4b7843bb1a55",
   "metadata": {},
   "source": [
    "We will now create an S3 bucket and upload the dataset into that bucket, which will be used in the fine-tuning job on Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589468f-b27f-4fd5-b3ff-bcb1998b1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path and S3 details\n",
    "bucket_name = 'bedrock-finetuning-bucket10092024'\n",
    "s3_key = abstracts_file\n",
    "\n",
    "# Specify the region\n",
    "bucket_region = 'us-east-1'  # Change this if needed\n",
    "\n",
    "# Initialize S3 client with the specified region\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "# Check if the bucket exists\n",
    "try:\n",
    "    existing_buckets = s3_client.list_buckets()\n",
    "    bucket_exists = any(bucket['Name'] == bucket_name for bucket in existing_buckets['Buckets'])\n",
    "\n",
    "    if not bucket_exists:\n",
    "        # Create the bucket based on the region\n",
    "        try:\n",
    "            if bucket_region == 'us-east-1':\n",
    "                # For us-east-1, do not specify LocationConstraint\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "                print(f\"Bucket {bucket_name} created successfully in us-east-1.\")\n",
    "            else:\n",
    "                # For other regions, specify the LocationConstraint\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': bucket_region}\n",
    "                )\n",
    "                print(f\"Bucket {bucket_name} created successfully in {bucket_region}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket: {e}\")\n",
    "            raise e\n",
    "    else:\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "\n",
    "    # Upload the file to S3\n",
    "    try:\n",
    "        s3_client.upload_file(output_file_path, bucket_name, s3_key)\n",
    "        print(f\"File uploaded to s3://{bucket_name}/{s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56295356-ebc3-4029-87b3-052e1894f58c",
   "metadata": {},
   "source": [
    "## Step 5: Fine-Tune the Model on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d601212c-26a1-4307-a667-4cb7789d33e2",
   "metadata": {},
   "source": [
    "Now, we create a fine-tuning job using Amazon Bedrock's API. We'll first list the available foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c860c0-0790-42bf-85da-3d4f82e110a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the AWS region and initialize the Bedrock client\n",
    "bedrock_region = \"us-east-1\"\n",
    "\n",
    "# Initialize the Bedrock client\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=bedrock_region)\n",
    "\n",
    "# List foundation models available for fine-tuning\n",
    "response = bedrock.list_foundation_models(byCustomizationType=\"FINE_TUNING\")\n",
    "\n",
    "# Display the available models\n",
    "for model in response[\"modelSummaries\"]:\n",
    "    print(f\"Model ID: {model['modelId']}\")\n",
    "    print(f\"Model Name: {model['modelName']}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475599f-c084-438f-b405-b7f447fd3ed5",
   "metadata": {},
   "source": [
    "## Step 6: Create an IAM Role for Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f54708-d343-46f1-9816-1812f04d60e2",
   "metadata": {},
   "source": [
    "We create an IAM role that Bedrock can assume to access S3 during the fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150afdd-8f23-4066-9ed7-a4905b03d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize IAM client\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "# Define role name and trust policy\n",
    "role_name = \"BedrockFineTuningRole\"\n",
    "role_description = \"Role for Bedrock fine-tuning job\"\n",
    "\n",
    "trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the IAM role\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(trust_policy),\n",
    "        Description=role_description\n",
    "    )\n",
    "    role_arn = response['Role']['Arn']\n",
    "    print(f\"Created role with ARN: {role_arn}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating role: {e}\")\n",
    "\n",
    "# Attach permission policies to allow access to S3\n",
    "permission_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{bucket_name}\",\n",
    "                f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "iam_client.put_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyName=\"BedrockFineTuningS3Policy\",\n",
    "    PolicyDocument=json.dumps(permission_policy)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33fd5a-bc0b-4786-a8ed-d5728395b3b8",
   "metadata": {},
   "source": [
    "## Step 7: Submit the Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50ecd1-bc37-46c5-831a-7b98e683ffe2",
   "metadata": {},
   "source": [
    "We submit the fine-tuning job with your custom model name and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7adc3-c0fc-4d71-8761-7da8074a90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the job parameters\n",
    "base_model_id = \"cohere.command-light-text-v14:7:4k\"\n",
    "job_name = \"cohere-Summarizer-medical-finetuning-job-v1\"\n",
    "model_name = \"cohere-Summarizer-medical-Tuned-v1\"\n",
    "\n",
    "# Submit the fine-tuning job\n",
    "bedrock.create_model_customization_job(\n",
    "    customizationType=\"FINE_TUNING\",\n",
    "    jobName=job_name,\n",
    "    customModelName=model_name,\n",
    "    roleArn=role_arn,\n",
    "    baseModelIdentifier=base_model_id,\n",
    "    hyperParameters={\n",
    "        \"epochCount\": \"1\", # 3 Adjust based on convergence and overfitting\n",
    "        \"batchSize\": \"8\", # 16 Adjust based on memory availability and training speed\n",
    "        \"learningRate\": \"0.00001\", # Adjust based on training stability and speed\n",
    "    },\n",
    "    trainingDataConfig={\"s3Uri\": f\"s3://{bucket_name}/{s3_key}\"},\n",
    "    outputDataConfig={\"s3Uri\": f\"s3://{bucket_name}/finetuned/\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62221d-3367-49a2-b71b-7262625936e6",
   "metadata": {},
   "source": [
    "You can check the job status (next step) to make sure if it is finished or still being trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ca9faa-b5fb-4139-ae32-aff148f4a091",
   "metadata": {},
   "source": [
    "## Step 8: Monitor the Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fae14d-6587-442c-98f6-74d313055833",
   "metadata": {},
   "source": [
    "We monitor the fine-tuning job status to check its progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4fc59a-373c-4c9d-b172-a08578d73202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the job status\n",
    "status = bedrock.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "print(f\"Job status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c67d3-2464-42bd-b2c9-acfa1b28bd53",
   "metadata": {},
   "source": [
    "## Step 9: Perform Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65278350-aa22-4cde-967b-1ff26ae43eb4",
   "metadata": {},
   "source": [
    "To use the model for inference, you need to purchase \"Provisioned Throughput.\" On Amazon Bedrock sidebar in your AWS console, go to \"Custom Models\" and then choose the \"Models\" tab, select the model you have trained, and then click on \"Purchase Provisioned Throughput.\" Give the provisioned throughput a name, select a commitment term (you can choose \"No Commitment\" for testing), and then click \"Purchase Provisioned Throughput.\" Once this is set up, you'll be able to use the model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4b018-65f6-49b9-8262-1f748fdcad3b",
   "metadata": {},
   "source": [
    "On Amazon Bedrock sidebar in your AWS console, go to \"Custom Models\" and then choose the \"Jobs\" tab. Here you cann see the status of the training job. Once the training job is finishedn the status will be changed to \"Complete\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c1b33-35fd-4a37-a9b8-cdf89fd01e9c",
   "metadata": {},
   "source": [
    "![Alt text](images/job-status.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355aed7-7435-47a6-95cf-cbedd21e0285",
   "metadata": {},
   "source": [
    "Once the job is \"Complete\", go to \"Custom Models\" and then choose the \"Models\" tab, select the model you have trained, and then click on \"Purchase Provisioned Throughput.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c083f-8b35-412e-8344-6db0527781ee",
   "metadata": {},
   "source": [
    "![Alt text](images/models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e4dbf-f45e-4c6a-96c0-7ea2210ada70",
   "metadata": {},
   "source": [
    "Give the provisioned throughput a name, select a commitment term (you can choose \"No Commitment\" for testing), and then click \"Purchase Provisioned Throughput.\" Once this is set up, you'll be able to use the model for inference. You can also see the estimated price for each commitment term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13c4ee-ff13-4513-8bde-05704f1f0e9d",
   "metadata": {},
   "source": [
    "![Alt text](images/provision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6c045b-a209-4471-8d78-b8c29f50f5c7",
   "metadata": {},
   "source": [
    "To access your deployed model endpoint, you need the model ARN. Navigate to \"Custom Models,\" then select the \"Models\" tab. Choose the model you’ve trained and copy the \"Model ARN\" for use in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab7949-d919-4b2f-930c-e74fd6f249d4",
   "metadata": {},
   "source": [
    "![Alt text](images/model-arn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f8bd3-191b-4b16-8b9b-1a9493db8c32",
   "metadata": {},
   "source": [
    "![Alt text](images/in-service.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c6e79-ab30-4671-bb4a-dc947d0ce3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock runtime client\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", region_name=bedrock_region)\n",
    "\n",
    "# Define a prompt for model inference\n",
    "prompt = \"\"\"\n",
    "Summarize the following medical abstract:\n",
    "This study investigates the impact of diabetes on cardiovascular health. The research involved a cohort of 200 patients \n",
    "with type 2 diabetes, tracking their cardiovascular events over a period of 5 years. The results indicate a significant \n",
    "correlation between diabetes duration and the incidence of heart disease.\n",
    "\"\"\"\n",
    "\n",
    "# Define the inference request body\n",
    "body = {\n",
    "    \"prompt\": prompt,\n",
    "    \"temperature\": 0.5,\n",
    "    \"p\": 0.9,\n",
    "    \"max_tokens\": 80,\n",
    "}\n",
    "\n",
    "# Specify the ARN of the custom model\n",
    "custom_model_arn = \"YOUR_MODEL_ARN\" #Put your model ARN here\n",
    "\n",
    "# Invoke the custom model for inference\n",
    "try:\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        modelId=custom_model_arn,\n",
    "        body=json.dumps(body)\n",
    "    )\n",
    "\n",
    "    # Read and parse the response\n",
    "    response_body = response['body'].read().decode('utf-8')\n",
    "    result = json.loads(response_body)\n",
    "\n",
    "    # Extract the summary from the response\n",
    "    summary_text = result['generations'][0]['text']\n",
    "    print(\"Extracted Summary:\", summary_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e5e5e-a4df-4b10-ada6-3535ffee3acd",
   "metadata": {},
   "source": [
    "You can also use the Playground to test your fine-tuned model. To do this, go to the **Test** section under **Playground** in the Amazon Bedrock console. Select your fine-tuned model, then enter your prompt to start testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a7a09-d48a-420d-b155-1b6d2fd9f180",
   "metadata": {},
   "source": [
    "![Alt text](images/playground.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507b7ca-323b-4b40-aa37-268d30b8bbda",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "<span style=\"color:red\">To avoid incurring additional costs, please ensure that you **remove any provisioned throughput**.</span>\n",
    "\n",
    "<span style=\"color:red\">You can remove provisioned throughput by navigating to the **Provisioned Throughput** section from the sidebar in the Amazon Bedrock console. Select the active provisioned throughput and delete it.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
